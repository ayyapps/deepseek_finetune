{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49e0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required package\n",
    "# If running in a notebook or interactive environment, use the following:\n",
    "# %pip install transformers[torch]\n",
    "# %pip install \"accelerate>=0.26.0\"\n",
    "# If running as a script, use: pip install huggingface_hub[hf_xet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68dba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI\\Deepseek_finetuning\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967274b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"text\": \"Patient: I have a headache.\\nDoctor: Please take rest and stay hydrated.\"},\n",
    "    {\"text\": \"Patient: My stomach is upset.\\nDoctor: Try a light diet and monitor your symptoms.\"},\n",
    "    {\"text\": \"Patient: I feel dizzy.\\nDoctor: Make sure you sit down and drink some water.\"},\n",
    "    {\"text\": \"Patient: I have a sore throat.\\nDoctor: Gargle with warm salt water and drink warm fluids.\"},\n",
    "    {\"text\": \"Patient: I am coughing a lot.\\nDoctor: Take honey with warm water and avoid cold drinks.\"},\n",
    "    {\"text\": \"Patient: I feel very tired.\\nDoctor: Ensure you get enough sleep and eat a balanced diet.\"},\n",
    "    {\"text\": \"Patient: I have body pain.\\nDoctor: Try a warm bath and consider a mild pain reliever.\"},\n",
    "    {\"text\": \"Patient: I feel anxious.\\nDoctor: Practice deep breathing and relaxation techniques.\"},\n",
    "    {\"text\": \"Patient: I have a mild fever.\\nDoctor: Take paracetamol and drink plenty of fluids.\"},\n",
    "    {\"text\": \"Patient: I have back pain.\\nDoctor: Maintain proper posture and apply a hot compress.\"},\n",
    "    {\"text\": \"Patient: I feel short of breath.\\nDoctor: Please sit upright and take slow deep breaths.\"},\n",
    "    {\"text\": \"Patient: I have a cold.\\nDoctor: Rest well and drink ginger tea with honey.\"},\n",
    "    {\"text\": \"Patient: I am not sleeping well.\\nDoctor: Avoid caffeine late in the day and try relaxation before bed.\"},\n",
    "    {\"text\": \"Patient: I have chest discomfort.\\nDoctor: Please avoid exertion and get a medical check immediately if it worsens.\"},\n",
    "    {\"text\": \"Patient: I feel weak after exercise.\\nDoctor: Rehydrate with water and include electrolytes if needed.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c9b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4402b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"text\"],\n",
    "                       truncation=True,\n",
    "                       max_length=64,      \n",
    "                       padding=\"max_length\")\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b70b4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 391.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d79b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI\\Deepseek_finetuning\\.venv\\lib\\site-packages\\transformers\\training_args.py:1583: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %pip install \"accelerate>=0.26.0\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fast_finetune\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=10,             \n",
    "    logging_steps=1,\n",
    "    no_cuda=True,             \n",
    "    fp16=False               \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1937aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc45a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:37<05:36, 37.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.8946, 'grad_norm': inf, 'learning_rate': 4.5e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [01:04<04:08, 31.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.3001, 'grad_norm': inf, 'learning_rate': 4e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:41<03:56, 33.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.5e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:14<03:21, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [02:50<02:52, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.5e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:25<02:18, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:02<01:46, 35.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.5e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [04:35<01:09, 34.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:08<00:34, 34.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [05:46<00:00, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [07:09<00:00, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 429.5922, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.023, 'train_loss': 1.9194735527038573, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [07:10<00:00, 43.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=1.9194735527038573, metrics={'train_runtime': 429.5922, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.023, 'total_flos': 4916780728320.0, 'train_loss': 1.9194735527038573, 'epoch': 0.6666666666666666})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f944a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fast_finetuned\\\\tokenizer_config.json',\n",
       " './fast_finetuned\\\\special_tokens_map.json',\n",
       " './fast_finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model('./fast_finetuned')\n",
    "tokenizer.save_pretrained('./fast_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239631e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_length = 64):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(**inputs, max_length = max_length)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21364298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chatbot response:', 'Patient: I have a headache!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n"
     ]
    }
   ],
   "source": [
    "prompt= 'Patient: I have a headache'\n",
    "print((\"chatbot response:\",generate_response(prompt) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
